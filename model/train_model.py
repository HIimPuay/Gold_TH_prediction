#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_model.py - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•: Linear Regression, Random Forest, XGBoost, LightGBM
"""

import argparse
import joblib
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.callbacks import EarlyStopping

import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# -------------------- Optional libs -------------------- #
try:
    import xgboost as xgb
    HAS_XGB = True
except Exception:
    HAS_XGB = False
    print("‚ö†Ô∏è  XGBoost not installed. Install: pip install xgboost")

try:
    import lightgbm as lgb
    HAS_LGB = True
except Exception:
    HAS_LGB = False
    print("‚ö†Ô∏è  LightGBM not installed. Install: pip install lightgbm")

# --- TensorFlow/Keras imports for LSTM ---
try:
    from tensorflow import keras
    from sklearn.preprocessing import MinMaxScaler
    HAS_TF = True
except Exception:
    HAS_TF = False
    print("‚ö†Ô∏è  TensorFlow/Keras not installed. Install: pip install tensorflow scikit-learn")

# ==================== PATH / CONFIG ==================== #

def find_project_root() -> Path:
    """‡∏´‡∏≤ root directory ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå (‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏´‡∏ô)"""
    current = Path.cwd()
    if current.name == "model":
        return current.parent
    if (current / "data" / "Feature_store").exists():
        return current
    if (current.parent / "data" / "Feature_store").exists():
        return current.parent
    return current

PROJECT_ROOT = find_project_root()
FEATURE_STORE = PROJECT_ROOT / "data" / "Feature_store" / "feature_store.csv"
MODEL_DIR = PROJECT_ROOT / "model"
RESULTS_DIR = PROJECT_ROOT / "results"

# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏°‡∏µ Bitcoin ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ)
BASE_VARS = ["gold", "fx", "cpi", "oil", "set"]
BTC_VARS = BASE_VARS + ["btc"]

# ==================== FUNCTIONS ==================== #

def load_data(path: Path) -> pd.DataFrame:
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å feature store"""
    if not Path(path).exists():
        raise FileNotFoundError(f"‚ùå Feature store not found at: {path}")
    df = pd.read_csv(path, parse_dates=["date"])
    df = df.sort_values("date").reset_index(drop=True)
    # ‡∏ï‡∏£‡∏ß‡∏à gold_next
    if "gold_next" not in df.columns:
        raise ValueError("‚ùå Missing target column 'gold_next' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå feature_store.csv")
    return df

def prepare_features(df: pd.DataFrame):
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    has_btc = "btc" in df.columns
    vars_list = BTC_VARS if has_btc else BASE_VARS
    
    feature_cols = []
    for var in vars_list:
        feature_cols.extend([
            f"{var}_lag1",
            f"{var}_lag3",
            f"{var}_roll7",
            f"{var}_pct"
        ])
    feature_cols.extend(vars_list)  # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á

    missing = [c for c in feature_cols if c not in df.columns]
    if missing:
        raise ValueError(f"Missing features: {missing}")

    X = df[feature_cols].copy()
    y = df["gold_next"].copy()

    valid_idx = ~(X.isna().any(axis=1) | y.isna())
    X = X[valid_idx]
    y = y[valid_idx]
    dates = df.loc[valid_idx, "date"]

    print(f"‚úÖ Features prepared: {len(feature_cols)} features, {len(X)} samples")
    print(f"üìä Has Bitcoin: {has_btc}")
    return X, y, dates, feature_cols

def get_models():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á dictionary ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    models = {
        "linear": LinearRegression(),
        "ridge": Ridge(alpha=1.0),
        "lasso": Lasso(alpha=0.1),
        "rf": RandomForestRegressor(
            n_estimators=200,
            max_depth=10,
            min_samples_split=5,
            random_state=42,
            n_jobs=-1
        ),
        "gbm": GradientBoostingRegressor(
            n_estimators=200,
            max_depth=5,
            learning_rate=0.08,
            random_state=42
        )
    }
    if HAS_XGB:
        models["xgb"] = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=5,
            learning_rate=0.06,
            subsample=0.9,
            colsample_bytree=0.9,
            random_state=42,
            n_jobs=-1,
            tree_method="hist"
        )
    if HAS_LGB:
        models["lgb"] = lgb.LGBMRegressor(
            n_estimators=500,
            max_depth=-1,
            learning_rate=0.05,
            subsample=0.9,
            colsample_bytree=0.9,
            random_state=42,
            n_jobs=-1,
            verbose=-1
        )

    # Add LSTM placeholder
    if HAS_TF:
        # ‡πÉ‡∏ä‡πâ LinearRegression ‡πÄ‡∏õ‡πá‡∏ô placeholder ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏¢‡∏Å
        models["lstm"] = LinearRegression()

    return models

def evaluate_model(model, X_test, y_test):
    """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    y_pred = model.predict(X_test)
    mae  = mean_absolute_error(y_test, y_pred)
    mse  = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2   = r2_score(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
    return {"MAE": mae, "MSE": mse, "RMSE": rmse, "R2": r2, "MAPE": mape}

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô evaluate_model(model, X_test, y_test)

def get_predictions(model, name, X_test, y_test, df_full, feature_cols, test_size):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ y_pred ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    if name != "lstm":
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Scikit-learn (Linear, RF, XGB, etc.)
        y_pred = model.predict(X_test)
        # ‡πÉ‡∏ä‡πâ y_test ‡∏à‡∏≤‡∏Å splits
        y_actual = y_test.values 
    else:
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞)
        TIME_STEP = 60
        df_lstm_for_plot = df_full.loc[X_test.index].copy() 

        X_train_lstm, Y_train_lstm, X_test_lstm, Y_test_actual, scaler, training_data_len = \
            prepare_lstm_data(df_lstm_for_plot, feature_cols, TIME_STEP, test_size)
            
        predictions_scaled = model.predict(X_test_lstm, verbose=0)

        # Inverse Transform
        n_features = scaler.n_features_in_
        predictions_dummy = np.zeros((predictions_scaled.shape[0], n_features))
        predictions_dummy[:, 0] = predictions_scaled.flatten() 
        predictions_unscaled = scaler.inverse_transform(predictions_dummy)[:, 0].flatten()

        # Trim Actuals and Predictions to match the effective prediction window
        start_index_trim = len(Y_test_actual) - len(predictions_unscaled)
        y_actual = Y_test_actual[start_index_trim:]
        y_pred = predictions_unscaled

    return y_actual, y_pred

def train_and_evaluate(models, X, y, test_size=0.2, random_state=42):
    """‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (time-ordered split)"""
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, shuffle=False
    )
    print(f"\nüìä Data split:\n   Train: {len(X_train)}\n   Test:  {len(X_test)}\n   Test ratio: {test_size*100:.0f}%")

    results, trained_models = {}, {}
    print("\nüîß Training models...\n" + "=" * 60)

    for name, model in models.items():
        print(f"\n‚öôÔ∏è  Training {name.upper()}...", end=" ")
        try:
            model.fit(X_train, y_train)
            metrics = evaluate_model(model, X_test, y_test)
            cv_scores = cross_val_score(
                model, X_train, y_train, cv=5,
                scoring='neg_mean_absolute_error', n_jobs=-1
            )
            metrics["CV_MAE"] = -cv_scores.mean()
            metrics["CV_STD"] = cv_scores.std()
            results[name] = metrics
            trained_models[name] = model
            print("‚úÖ")
            print(f"   MAE:  {metrics['MAE']:.2f} ‡∏ö‡∏≤‡∏ó | RMSE: {metrics['RMSE']:.2f} ‡∏ö‡∏≤‡∏ó | R¬≤: {metrics['R2']:.4f} | MAPE: {metrics['MAPE']:.2f}%")
        except Exception as e:
            print(f"‚ùå Error: {e}")
    return results, trained_models, (X_train, X_test, y_train, y_test)

# -------------------- LSTM FUNCTIONS -------------------- #

def prepare_lstm_data(df: pd.DataFrame, feature_cols: list, TIME_STEP: int, test_size: float):
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Scaling + Sliding Window) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LSTM"""
    
    # 1. Cleaning and Scaling
    data_for_lstm = df[feature_cols].values 
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data_for_lstm)

    # 2. Split (Time-based split, using the same ratio as sklearn split)
    dataset_len = len(df)
    training_data_len = int(np.ceil(dataset_len * (1 - test_size)))

    training_data = scaled_data[:training_data_len] 
    # ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏ß‡∏° TIME_STEP ‡∏ß‡∏±‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Train set ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á Window ‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á Test set
    test_data_split = scaled_data[training_data_len - TIME_STEP:] 

    # 3. Create Sliding Window for Train Set
    X_train_lstm, Y_train_lstm = [], []
    for i in range(TIME_STEP, len(training_data)):
        X_train_lstm.append(training_data[i - TIME_STEP:i, :]) 
        Y_train_lstm.append(training_data[i, 0]) # Target is 'gold' (index 0)

    X_train_lstm, Y_train_lstm = np.array(X_train_lstm), np.array(Y_train_lstm)

    # 4. Create Sliding Window for Test Set
    X_test_lstm = []
    for i in range(TIME_STEP, len(test_data_split)):
        X_test_lstm.append(test_data_split[i - TIME_STEP:i, :])
    
    X_test_lstm = np.array(X_test_lstm)

    # 5. Extract unscaled actual Y_test for metrics calculation
    # Y_test_actual: ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥‡∏à‡∏£‡∏¥‡∏á (Unscaled) ‡∏Ç‡∏≠‡∏á Test Set
    Y_test_actual = df["gold_next"].values[training_data_len:]

    return X_train_lstm, Y_train_lstm, X_test_lstm, Y_test_actual, scaler, training_data_len


def build_lstm_model(input_shape):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÅ‡∏ö‡∏ö Multivariate"""
    model = keras.models.Sequential()
    
    model.add(keras.layers.LSTM(64, return_sequences=True, input_shape=input_shape))
    model.add(keras.layers.LSTM(64, return_sequences=False))
    model.add(keras.layers.Dense(128, activation="relu"))
    model.add(keras.layers.Dense(1)) 

    return model


def train_and_evaluate_lstm(df: pd.DataFrame, feature_cols: list, test_size: float) -> tuple[dict, dict, str]:
    """‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞"""

    TIME_STEP = 60 # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 60 ‡∏ß‡∏±‡∏ô
    MODEL_NAME = "lstm"
    
    print("\n" + "=" * 60)
    print(f"üîß Starting {MODEL_NAME.upper()} Model (TIME_STEP={TIME_STEP}) Training...")
    
    try:
        X_train_lstm, Y_train_lstm, X_test_lstm, Y_test_actual, scaler, training_data_len = \
            prepare_lstm_data(df, feature_cols, TIME_STEP, test_size)
        
        input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])
        lstm_model = build_lstm_model(input_shape)

        # 1. Compile and Train
        lstm_model.compile(optimizer="adam", loss="mae", metrics=[keras.metrics.RootMeanSquaredError()])
        
        # *** ‡πÄ‡∏û‡∏¥‡πà‡∏° Early Stopping ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á ***
        # ‡πÉ‡∏ä‡πâ patience 20 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏Å‡∏¥‡∏ô 20 epochs
        es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, mode='min', restore_best_weights=True)

        print("   Training LSTM for 150 epochs...", end=" ")
        history = lstm_model.fit(
            X_train_lstm, 
            Y_train_lstm, 
            epochs=300, # ‡πÄ‡∏û‡∏¥‡πà‡∏° Epochs ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Early Stopping ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
            batch_size=32, 
            verbose=0,
            validation_split=0.1, # ‡πÉ‡∏ä‡πâ 10% ‡∏Ç‡∏≠‡∏á Training Data ‡πÄ‡∏õ‡πá‡∏ô Validation Set
            callbacks=[es]
        )
        print("‚úÖ")

        # 2. Predict
        predictions_scaled = lstm_model.predict(X_test_lstm, verbose=0)

        # 3. Inverse Transform (Requires a dummy array of size n_features)
        n_features = scaler.n_features_in_
        predictions_dummy = np.zeros((predictions_scaled.shape[0], n_features))
        predictions_dummy[:, 0] = predictions_scaled.flatten() # Gold is at index 0

        predictions_unscaled = scaler.inverse_transform(predictions_dummy)[:, 0].flatten()

        # 4. Trim Actuals to match predictions size
        start_index = len(Y_test_actual) - len(predictions_unscaled)
        Y_test_actual_trimmed = Y_test_actual[start_index:]
        
        # 5. Calculate Metrics
        mae  = mean_absolute_error(Y_test_actual_trimmed, predictions_unscaled)
        mse  = mean_squared_error(Y_test_actual_trimmed, predictions_unscaled)
        rmse = np.sqrt(mse)
        # R2 ‡πÅ‡∏•‡∏∞ CV_MAE/STD ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
        mape = np.mean(np.abs((Y_test_actual_trimmed - predictions_unscaled) / Y_test_actual_trimmed)) * 100
        
        lstm_metrics = {"MAE": mae, "MSE": mse, "RMSE": rmse, "R2": None, "MAPE": mape, "CV_MAE": None, "CV_STD": None}
        
        print(f"   MAE:  {lstm_metrics['MAE']:.2f} ‡∏ö‡∏≤‡∏ó | RMSE: {lstm_metrics['RMSE']:.2f} ‡∏ö‡∏≤‡∏ó | MAPE: {lstm_metrics['MAPE']:.2f}%")
        
        # Return in the same format as the main training function
        return {MODEL_NAME: lstm_metrics}, {MODEL_NAME: lstm_model}, MODEL_NAME

    except Exception as e:
        print(f"‚ùå Error during {MODEL_NAME.upper()} training/evaluation: {e}")
        # ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î Error ‡πÉ‡∏´‡πâ return dictionary ‡∏ß‡πà‡∏≤‡∏á
        return {}, {}, None

# -------------------- END LSTM FUNCTIONS -------------------- #

def save_results(results, feature_cols, output_dir: Path):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    output_dir.mkdir(parents=True, exist_ok=True)
    df_results = pd.DataFrame(results).T.sort_values("MAE")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_path = output_dir / f"model_comparison_{timestamp}.csv"
    df_results.to_csv(results_path)
    print("\n" + "=" * 60)
    print("üìä MODEL COMPARISON RESULTS")
    print("=" * 60)
    print(df_results.to_string())
    print(f"\nüíæ Results saved to: {results_path}")
    return df_results

def save_best_model(trained_models, results, output_dir: Path, feature_cols):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å MAE ‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î)"""
    output_dir.mkdir(parents=True, exist_ok=True)
    best_name = min(results.items(), key=lambda x: x[1]["MAE"])[0]
    best_model = trained_models[best_name]

    # model_path = output_dir / "best_model.pkl"
    # joblib.dump(best_model, model_path)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    if best_name == "lstm":
        model_path = output_dir / "best_model_lstm.keras"
        best_model.save(model_path)
        print(f"\n‚úÖ Best model ({best_name.upper()}) saved (Keras format) to: {model_path}")
    else:
        model_path = output_dir / "best_model.pkl"
        joblib.dump(best_model, model_path)
        print(f"\n‚úÖ Best model ({best_name.upper()}) saved (Joblib format) to: {model_path}")

    metadata = {
        "model_type": best_name,
        "feature_count": len(feature_cols),
        "features": feature_cols,
        "metrics": results[best_name],
        "trained_at": datetime.now().isoformat()
    }
    metadata_path = output_dir / "model_metadata.pkl"
    joblib.dump(metadata, metadata_path)

    print(f"\n‚úÖ Best model ({best_name.upper()}) saved to: {model_path}")
    print(f"   MAE: {results[best_name]['MAE']:.2f} ‡∏ö‡∏≤‡∏ó | RMSE: {results[best_name]['RMSE']:.2f} ‡∏ö‡∏≤‡∏ó")
    return best_model, best_name

# -------------------- PLOTTING FUNCTION (NEW) -------------------- #

def plot_predictions(trained_models, df_full, feature_cols, splits, dates_full, test_size, output_dir):
    """‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡∏ö‡∏ô Test Set ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
    
    # Unpack splits
    X_train, X_test, y_train, y_test = splits

    # Dataframe to store predictions
    # ‡πÉ‡∏ä‡πâ dates ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö index ‡∏Ç‡∏≠‡∏á X_test
    dates_test = dates_full.loc[X_test.index].reset_index(drop=True)
    df_plot = pd.DataFrame({'date': dates_test, 'Actual': y_test.values})

    print("\nüìà Generating prediction comparison plot...")
    
    # Get predictions for all models
    for name, model in trained_models.items():
        # y_actual_trimmed ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö y_pred (y_test ‡∏´‡∏£‡∏∑‡∏≠ y_test ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πâ‡∏ô‡∏≠‡∏≠‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LSTM)
        y_actual_trimmed, y_pred = get_predictions(
            model, name, X_test, y_test, df_full, feature_cols, test_size
        )
        
        # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        if name != "lstm":
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà LSTM, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° X_test ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            df_plot[f'{name.upper()}_Pred'] = y_pred
        else:
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LSTM, ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ TIME_STEP ‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á Test Set
            # ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏≤ index ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á LSTM
            start_index_trim = len(df_plot) - len(y_pred)
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LSTM predictions ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πâ‡∏ô‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß
            df_lstm_plot = pd.DataFrame({
                'date': dates_test[start_index_trim:].reset_index(drop=True),
                f'{name.upper()}_Pred': y_pred
            })
            # Merge LSTM predictions ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö DataFrame ‡∏´‡∏•‡∏±‡∏Å‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ 'date'
            df_plot = pd.merge(df_plot, df_lstm_plot, on='date', how='left')
            
        print(f"   {name.upper()} predictions added (Length: {len(y_pred)})")


    # --- Matplotlib Plotting ---
    plt.style.use('ggplot')
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü
    fig_width = max(15, len(df_plot) / 15) 
    fig, ax = plt.subplots(figsize=(fig_width, 8))

    # ‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á (‡πÄ‡∏™‡πâ‡∏ô‡∏™‡∏µ‡∏î‡∏≥‡∏´‡∏ô‡∏≤)
    ax.plot(df_plot['date'], df_plot['Actual'], label='Actual Gold Price', 
            color='black', linewidth=3, alpha=0.9)

    # ‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
    # ‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏´‡∏°‡πà: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏ä‡∏∏‡∏î‡∏™‡∏µ 'tab10' ‡∏´‡∏£‡∏∑‡∏≠ 'Set1' (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å)
    model_preds = [col for col in df_plot.columns if '_Pred' in col]
    
    # ‡πÉ‡∏ä‡πâ colormap 'tab10' ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ 10 ‡∏™‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
    color_mapping = {
        'RIDGE_Pred': 'blue', 
        'LINEAR_Pred': 'green',
        'LASSO_Pred': 'purple',
        'RF_Pred': 'orange',
        'GBM_Pred': 'brown',
        'LSTM_Pred': 'red',
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
    }

    colors_map = plt.cm.get_cmap('tab10')
    
    # ‡πÉ‡∏ô Loop ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    for i, col in enumerate(model_preds):
        # ‡πÉ‡∏ä‡πâ‡∏™‡∏µ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á‡∏à‡∏≤‡∏Å color_mapping 
        # ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏µ‡∏à‡∏≤‡∏Å colormap ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (tab10)
        plot_color = color_mapping.get(col, colors_map(i)) 
        
        ax.plot(df_plot['date'], df_plot[col], 
                label=col.replace('_Pred', ''), 
                color=plot_color, 
                linestyle='--', 
                alpha=0.7)
    
    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
    ax.set_title(f'Gold Price Prediction Comparison on Test Set (Test Size: {test_size*100:.0f}%)', fontsize=16)
    ax.set_xlabel('Date', fontsize=12)
    ax.set_ylabel('Gold Price (THB)', fontsize=12)
    ax.legend(loc='best', fontsize=10, ncol=min(3, len(model_preds)+1))
    ax.grid(True, linestyle=':', alpha=0.6)

    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏ô‡πÅ‡∏Å‡∏ô x
    formatter = mdates.DateFormatter("%Y-%m-%d")
    ax.xaxis.set_major_formatter(formatter)
    fig.autofmt_xdate(rotation=45) 
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏£‡∏≤‡∏ü
    output_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_path = output_dir / f"predictions_comparison_{timestamp}.png"
    plt.tight_layout()
    plt.savefig(plot_path)
    plt.close()

    print(f"üíæ Prediction comparison plot saved to: {plot_path}")
    return df_plot

# -------------------- END PLOTTING FUNCTION -------------------- #


def main(args):
    # parser = argparse.ArgumentParser(description="Train gold price prediction model")
    # parser.add_argument("--data", type=Path, default=FEATURE_STORE, help="Path to feature store")
    # parser.add_argument("--model-dir", type=Path, default=MODEL_DIR, help="Output directory for model")
    # parser.add_argument("--results-dir", type=Path, default=RESULTS_DIR, help="Output directory for results")
    # parser.add_argument("--test-size", type=float, default=0.2, help="Test set size (0-1)")
    # parser.add_argument("--plot", action="store_true", help="Generate prediction plots")
    # args = parser.parse_args()

    print("üöÄ Starting Gold Price Prediction Model Training")
    print("=" * 60)

    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    print(f"\nüìÅ Loading data from: {args.data}")
    df = load_data(args.data)
    print(f"   Loaded {len(df)} rows")
    print(f"   Date range: {df['date'].min().date()} to {df['date'].max().date()}")

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå
    X, y, dates, feature_cols = prepare_features(df)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    models = get_models()

    # ‡πÅ‡∏¢‡∏Å LSTM placeholder model ‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ train ‡∏î‡πâ‡∏ß‡∏¢ Scikit-learn
    lstm_placeholder_model = models.pop("lstm", None)

    print(f"\nüéØ Available models: {', '.join(models.keys()).upper()}")

    # ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
    results, trained_models, splits = train_and_evaluate(
        models, X, y, test_size=args.test_size
    )

    # 2. --- LSTM MODEL TRAINING (If available) ---
    if HAS_TF and lstm_placeholder_model:
        # Ensure only rows that were valid in SKLearn split are used, to maintain test set integrity
        df_lstm = df.loc[X.index].copy() 

        lstm_results, lstm_trained_models, _ = train_and_evaluate_lstm(
            df_lstm, 
            feature_cols, 
            args.test_size
        )
        
        # Merge LSTM results with Sklearn results
        results.update(lstm_results)
        trained_models.update(lstm_trained_models)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    df_results = save_results(results, feature_cols, args.results_dir)

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    best_model, best_name = save_best_model(
        trained_models, results, args.model_dir, feature_cols
    )

    # --- ADDED: PLOT PREDICTIONS ---
    if args.plot: 
        df_predictions = plot_predictions(
            trained_models, 
            df, 
            feature_cols, 
            splits, 
            dates, 
            args.test_size, 
            args.results_dir
        )

    print("\n‚úÖ Training complete!")
    print("=" * 60)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Train gold price prediction model")
    parser.add_argument("--data", type=Path, default=FEATURE_STORE, help="Path to feature store")
    parser.add_argument("--model-dir", type=Path, default=MODEL_DIR, help="Output directory for model")
    parser.add_argument("--results-dir", type=Path, default=RESULTS_DIR, help="Output directory for results")
    parser.add_argument("--test-size", type=float, default=0.2, help="Test set size (0-1)")
    parser.add_argument("--plot", action="store_true", help="Generate prediction plots")
    args = parser.parse_args()

    main(args)
